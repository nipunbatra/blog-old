{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with prior (using gradient descent)\n",
    "> What if we start from some prior!\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Nipun Batra\n",
    "- categories: [ML]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a prior on the linear model, i.e. we start with a known W (W_prior) and b (b_prior). Further, we say that the learnt function can be such that:\n",
    "\n",
    "$$W = \\alpha \\times W_{prior} + \\delta$$\n",
    "$$b = \\beta + b_{prior} + \\eta$$\n",
    "\n",
    "Our task reduces to learn $\\alpha$, $\\beta$, $\\delta$ and $\\eta$. This can be solved as we would usually do using Gradient descent, the only difference being that we will compute the gradient wrt $\\alpha$ , $\\beta$, $\\delta$, $\\eta$. I will use autograd to compute the gradients.\n",
    "\n",
    "In a typical model we might have 2 parameters (w and b). In our `refined` one, we have four- $\\alpha$ , $\\beta$, $\\delta$, $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True model  \n",
    "\n",
    "$$Y = 10 X + 6$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n_samples = 50\n",
    "X = np.linspace(1, 50, n_samples)\n",
    "Y = 10*X + 6 + 3*np.random.randn(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEPCAYAAAC3NDh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1MqQkCS1MiQkSa3+P3BsI88cBTlyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10463fd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, Y, 'k.')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining priors (bad ones!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_prior = -2\n",
    "b_prior = -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the cost function in terms of alpha and beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(alpha, beta, delta, eta):\n",
    "    pred = np.dot(X, alpha*w_prior+delta) + b_prior + beta + eta\n",
    "    return np.sqrt(((pred - Y) ** 2).mean(axis=None))\n",
    "\n",
    "from autograd import grad, multigrad\n",
    "grad_cost= multigrad(cost, argnums=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "0\n",
      "********************\n",
      "277.717926153 0.756766902473 0.756766902473\n",
      "********************\n",
      "500\n",
      "********************\n",
      "5.95005440573 10.218493676 10.218493676\n",
      "********************\n",
      "1000\n",
      "********************\n",
      "5.77702829051 10.2061390906 10.2061390906\n",
      "********************\n",
      "1500\n",
      "********************\n",
      "5.60823669668 10.1939366275 10.1939366275\n",
      "********************\n",
      "2000\n",
      "********************\n",
      "5.44395500928 10.1818982949 10.1818982949\n",
      "********************\n",
      "2500\n",
      "********************\n",
      "5.28446602486 10.1700368748 10.1700368748\n",
      "********************\n",
      "3000\n",
      "********************\n",
      "5.1300568557 10.158365894 10.158365894\n",
      "********************\n",
      "3500\n",
      "********************\n",
      "4.98101499128 10.1468995681 10.1468995681\n",
      "********************\n",
      "4000\n",
      "********************\n",
      "4.83762347034 10.1356527141 10.1356527141\n",
      "********************\n",
      "4500\n",
      "********************\n",
      "4.70015516667 10.1246406278 10.1246406278\n",
      "********************\n",
      "5000\n",
      "********************\n",
      "4.56886626032 10.1138789219 10.1138789219\n",
      "********************\n",
      "5500\n",
      "********************\n",
      "4.44398905185 10.1033833225 10.1033833225\n",
      "********************\n",
      "6000\n",
      "********************\n",
      "4.32572437603 10.0931694258 10.0931694258\n",
      "********************\n",
      "6500\n",
      "********************\n",
      "4.21423397192 10.0832524173 10.0832524173\n",
      "********************\n",
      "7000\n",
      "********************\n",
      "4.10963325557 10.0736467626 10.0736467626\n",
      "********************\n",
      "7500\n",
      "********************\n",
      "4.01198500112 10.0643658801 10.0643658801\n",
      "********************\n",
      "8000\n",
      "********************\n",
      "3.92129444852 10.0554218111 10.0554218111\n",
      "********************\n",
      "8500\n",
      "********************\n",
      "3.83750630808 10.046824905 10.046824905\n",
      "********************\n",
      "9000\n",
      "********************\n",
      "3.7605040187 10.0385835381 10.0385835381\n",
      "********************\n",
      "9500\n",
      "********************\n",
      "3.69011144573 10.0307038843 10.0307038843\n",
      "********************\n",
      "10000\n",
      "********************\n",
      "3.6260969956 10.023189752 10.023189752\n"
     ]
    }
   ],
   "source": [
    "alpha = np.random.randn()\n",
    "beta = np.random.randn()\n",
    "eta = np.random.randn()\n",
    "delta = np.random.randn()\n",
    "lr = 0.001\n",
    "# We will also save the values for plotting later\n",
    "w_s = [alpha*w_prior+delta]\n",
    "b_s = [alpha*w_prior+delta]\n",
    "for i in range(10001):\n",
    "    \n",
    "    del_alpha, del_beta, del_delta, del_eta = grad_cost(alpha, beta, delta, eta)\n",
    "    alpha = alpha - del_alpha*lr\n",
    "    beta = beta - del_beta*lr\n",
    "    delta = delta - del_delta*lr\n",
    "    eta = eta - del_eta*lr\n",
    "    w_s.append(alpha*w_prior+delta)\n",
    "    b_s.append(alpha*w_prior+delta)\n",
    "    if i%500==0:\n",
    "        print \"*\"*20\n",
    "        print i\n",
    "        print \"*\"*20\n",
    "    \n",
    "        print cost(alpha, beta, delta, eta), alpha*w_prior+delta, alpha*w_prior+delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to learn a reasonably accurate W=10.07 and b=2.7. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the plots look nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_axes(ax):\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    for spine in ['left', 'bottom']:\n",
    "        ax.spines[spine].set_color('grey')\n",
    "        ax.spines[spine].set_linewidth(0.5)\n",
    "\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_tick_params(direction='out', color='grey')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fig size: 72.0 DPI, size in inches [ 4.  3.]\n"
     ]
    }
   ],
   "source": [
    "# Code courtesy: http://eli.thegreenplace.net/2016/drawing-animated-gifs-with-matplotlib/\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "# Query the figure's on-screen size and DPI. Note that when saving the figure to\n",
    "# a file, we need to provide a DPI for that separately.\n",
    "print('fig size: {0} DPI, size in inches {1}'.format(\n",
    "    fig.get_dpi(), fig.get_size_inches()))\n",
    "\n",
    "# Plot a scatter that persists (isn't redrawn) and the initial line.\n",
    "\n",
    "ax.scatter(X, Y, color='grey', alpha=0.8, s=1)\n",
    "# Initial line\n",
    "\n",
    "line, = ax.plot(X, X*w_prior+b_prior, 'r-', linewidth=1)\n",
    "\n",
    "def update(i):\n",
    "    label = 'Iteration {0}'.format(i)\n",
    "    line.set_ydata(X*w_s[i]+b_s[i])\n",
    "    ax.set_xlabel(label)\n",
    "    format_axes(ax)\n",
    "    return line, ax\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, 100), interval=1)\n",
    "anim.save('line_prior.gif', dpi=80, writer='imagemagick')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://nipunbatra.github.io/blog/images/line_prior.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
